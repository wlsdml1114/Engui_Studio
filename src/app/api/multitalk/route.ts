// src/app/api/multitalk/route.ts

import { NextRequest, NextResponse } from 'next/server';
import { PrismaClient } from '@prisma/client';
import RunPodService from '@/lib/runpodService';
import SettingsService from '@/lib/settingsService';
import S3Service from '@/lib/s3Service';
import { writeFileSync, mkdirSync } from 'fs';
import { join } from 'path';

const prisma = new PrismaClient();
const settingsService = new SettingsService();

// Î°úÏª¨ Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
const LOCAL_STORAGE_DIR = join(process.cwd(), 'public', 'results');

// ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏúºÎ©¥ ÏÉùÏÑ±
try {
    mkdirSync(LOCAL_STORAGE_DIR, { recursive: true });
} catch (error) {
    console.log('üìÅ Results directory already exists or cannot be created');
}

export async function POST(request: NextRequest) {
    try {
        console.log('üé≠ Processing MultiTalk generation request...');

        const formData = await request.formData();

        // Extract form data
        const userId = formData.get('userId') as string;
        const audioMode = formData.get('audioMode') as string;
        const prompt = formData.get('prompt') as string || 'a person talking';
        
        console.log('üìã FormData extracted values:');
        console.log('  - userId:', userId);
        console.log('  - audioMode:', audioMode, '(type:', typeof audioMode, ')');
        console.log('  - prompt:', prompt);
        
        // Load user settings
        console.log('üìñ Loading user settings...');
        const { settings } = await settingsService.getSettings(userId);

        // Get current workspace ID
        const currentWorkspaceId = await settingsService.getCurrentWorkspaceId(userId);
        
        // Validate RunPod configuration
        if (!settings.runpod || typeof settings.runpod === 'string' || typeof settings.runpod === 'number' || 
            !(settings.runpod as any).apiKey || !(settings.runpod as any).endpoints?.multitalk) {
            return NextResponse.json({
                error: 'RunPod configuration incomplete. Please configure your API key and MultiTalk endpoint in Settings.',
                requiresSetup: true,
            }, { status: 400 });
        }
        
        // Type assertion for settings
        const runpodSettings = settings.runpod as any;

        const imageFile = formData.get('image') as File;
        const audio1File = formData.get('audio1') as File;
        const audio2File = formData.get('audio2') as File | null;

        // Validate required files
        if (!imageFile || !audio1File) {
            return NextResponse.json(
                { error: 'Image and at least one audio file are required' },
                { status: 400 }
            );
        }

        if (audioMode === 'dual' && !audio2File) {
            return NextResponse.json(
                { error: 'Second audio file is required for dual mode' },
                { status: 400 }
            );
        }

        // Î°úÏª¨ ÌååÏùº Ï†ïÎ≥¥ Ï†ÄÏû• (Ïç∏ÎÑ§ÏùºÏö©)
        const localFileInfo = {
            image: {
                name: imageFile.name,
                size: imageFile.size,
                type: imageFile.type,
                lastModified: imageFile.lastModified
            },
            audio1: {
                name: audio1File.name,
                size: audio1File.size,
                type: audio1File.type,
                lastModified: audio1File.lastModified
            },
            ...(audio2File && {
                audio2: {
                    name: audio2File.name,
                    size: audio2File.size,
                    type: audio2File.type,
                    lastModified: audio2File.lastModified
                }
            })
        };

        console.log('üìÅ Local file info:', localFileInfo);

        // Create job record in database
        const job = await prisma.job.create({
            data: {
                id: Math.random().toString(36).substring(2, 15),
                userId,
                workspaceId: currentWorkspaceId,
                status: 'processing',
                type: 'multitalk',
                prompt,
                options: JSON.stringify({ audioMode }),
                createdAt: new Date(),
            },
        });

        console.log(`üìù Created job record: ${job.id}`);

        // Deduct credit
        await prisma.creditActivity.create({
            data: {
                userId,
                activity: `Generated MultiTalk content (Job ID: ${job.id})`,
                amount: -2, // MultiTalk costs more credits
            },
        });

        // ÌååÏùºÎì§ÏùÑ S3Ïóê ÏóÖÎ°úÎìú
        console.log('üì§ Uploading files to S3...');
        const s3Service = new S3Service();
        
        const imageBuffer = Buffer.from(await imageFile.arrayBuffer());
        const audio1Buffer = Buffer.from(await audio1File.arrayBuffer());
        
        // Ïù¥ÎØ∏ÏßÄ ÌååÏùº S3 ÏóÖÎ°úÎìú
        const imageUpload = await s3Service.uploadFile(imageBuffer, imageFile.name, imageFile.type);
        console.log('‚úÖ Image uploaded to S3:', imageUpload);
        
        // Ïò§ÎîîÏò§1 ÌååÏùº S3 ÏóÖÎ°úÎìú
        const audio1Upload = await s3Service.uploadFile(audio1Buffer, audio1File.name, audio1File.type);
        console.log('‚úÖ Audio1 uploaded to S3:', audio1Upload);
        
        let audio2Upload: { s3Url: string; filePath: string } | undefined;
        if (audio2File) {
            const audio2Buffer = Buffer.from(await audio2File.arrayBuffer());
            audio2Upload = await s3Service.uploadFile(audio2Buffer, audio2File.name, audio2File.type);
            console.log('‚úÖ Audio2 uploaded to S3:', audio2Upload);
        }

        // ÌååÏùºÎì§ÏùÑ Î°úÏª¨ÏóêÎèÑ Ï†ÄÏû• (Î∞±ÏóÖÏö©)
        const imagePath = join(LOCAL_STORAGE_DIR, `input_${job.id}_${imageFile.name}`);
        const audio1Path = join(LOCAL_STORAGE_DIR, `input_${job.id}_${audio1File.name}`);
        
        let audio2Path: string | undefined;
        if (audio2File) {
            audio2Path = join(LOCAL_STORAGE_DIR, `input_${job.id}_${audio2File.name}`);
            
            try {
                const audio2Buffer = Buffer.from(await audio2File.arrayBuffer());
                writeFileSync(audio2Path, audio2Buffer);
                console.log('‚úÖ Audio2 saved locally:', audio2Path);
            } catch (saveError) {
                console.error('‚ùå Failed to save audio2 locally:', saveError);
                // S3 ÏóÖÎ°úÎìúÎäî ÏÑ±Í≥µÌñàÏúºÎØÄÎ°ú Í≥ÑÏÜç ÏßÑÌñâ
            }
        }

        try {
            writeFileSync(imagePath, imageBuffer);
            writeFileSync(audio1Path, audio1Buffer);
            console.log('‚úÖ Files saved locally (backup):', { imagePath, audio1Path });
        } catch (saveError) {
            console.error('‚ùå Failed to save files locally (backup):', saveError);
            // S3 ÏóÖÎ°úÎìúÎäî ÏÑ±Í≥µÌñàÏúºÎØÄÎ°ú Í≥ÑÏÜç ÏßÑÌñâ
        }

        // Prepare RunPod input - S3 Í≤ΩÎ°ú ÏÇ¨Ïö©
        console.log('üîß Preparing RunPod input...');
        console.log('  - audioMode:', audioMode);
        console.log('  - audio2File exists:', !!audio2File);
        console.log('  - audio2Upload exists:', !!audio2Upload);
        console.log('  - Will set audio_type to "para":', audioMode === 'dual');
        
        // S3 Í≤ΩÎ°ú ÏÇ¨Ïö© (runpod-volume ÌòïÏãù)
        const runpodInput = {
            prompt: prompt || "a man talking",
            image_path: imageUpload.filePath, // S3 Í≤ΩÎ°ú (/runpod-volume/...)
            audio_paths: {
                person1: audio1Upload.filePath, // S3 Í≤ΩÎ°ú (/runpod-volume/...)
                ...(audioMode === 'dual' && audio2Upload && { person2: audio2Upload.filePath }), // ÎìÄÏñº Î™®ÎìúÏùº ÎïåÎßå person2 Ï∂îÍ∞Ä
            },
        };

        // ÎìÄÏñº Ïò§ÎîîÏò§ Î™®ÎìúÏùº Îïå audio_typeÏùÑ paraÎ°ú ÏÑ§Ï†ï
        if (audioMode === 'dual') {
            (runpodInput as any).audio_type = 'para';
            console.log('‚úÖ audio_type set to "para" for dual mode');
        }

        console.log('üîß Final RunPod input structure (S3 paths):');
        console.log('  - prompt:', runpodInput.prompt);
        console.log('  - image_path:', runpodInput.image_path);
        console.log('  - audio_paths:', runpodInput.audio_paths);
        console.log('  - audioMode:', audioMode);
        console.log('  - audio2File exists:', !!audio2File);
        console.log('  - audio2Upload exists:', !!audio2Upload);
        console.log('  - audio_type:', (runpodInput as any).audio_type);
        console.log('  - Full RunPod input:', JSON.stringify(runpodInput, null, 2));

        console.log('üöÄ Submitting job to RunPod...', runpodInput);

        // Submit job to RunPod using user settings
        let runpodJobId: string;
        try {
            console.log('üîß Creating RunPod service with user settings...');
            const runpodService = new RunPodService(
                runpodSettings.apiKey,
                runpodSettings.endpoints.multitalk,
                runpodSettings.generateTimeout || 3600 // Generate ÌÉÄÏûÑÏïÑÏõÉ ÏÑ§Ï†ï Ï†ÑÎã¨
            );

            console.log('üîß Submitting to RunPod with input:', JSON.stringify(runpodInput, null, 2));
            runpodJobId = await runpodService.submitJob(runpodInput);

            console.log(`‚úÖ RunPod job submitted successfully: ${runpodJobId}`);
        } catch (runpodError) {
            console.error('‚ùå RunPod submission failed:', runpodError);

            // Update job status to failed
            await prisma.job.update({
                where: { id: job.id },
                data: {
                    status: 'failed',
                    completedAt: new Date(),
                },
            });

            return NextResponse.json({
                error: `RunPod submission failed: ${runpodError}`,
                jobId: job.id,
                status: 'failed',
            }, { status: 500 });
        }

        // Update job with RunPod job ID and S3 paths
        await prisma.job.update({
            where: { id: job.id },
            data: {
                options: JSON.stringify({
                    audioMode,
                    runpodJobId,
                    // S3 ÏóÖÎ°úÎìú Ï†ïÎ≥¥
                    imageS3Url: imageUpload.s3Url,
                    imageS3Path: imageUpload.filePath,
                    audio1S3Url: audio1Upload.s3Url,
                    audio1S3Path: audio1Upload.filePath,
                    ...(audio2Upload && {
                        audio2S3Url: audio2Upload.s3Url,
                        audio2S3Path: audio2Upload.filePath,
                    }),
                    // Î°úÏª¨ ÌååÏùº Í≤ΩÎ°úÎì§ (Î∞±ÏóÖÏö©)
                    imagePath,
                    audio1Path,
                    audio2Path,
                    // Î°úÏª¨ Ïù¥ÎØ∏ÏßÄ Ïõπ Í≤ΩÎ°ú (Ïù¥ÎØ∏ÏßÄ ÌëúÏãúÏö©)
                    imageWebPath: `/results/input_${job.id}_${imageFile.name}`,
                    // Î°úÏª¨ ÌååÏùº Ï†ïÎ≥¥
                    localFileInfo,
                }),
            },
        });

        console.log(`‚úÖ MultiTalk job submitted: ${job.id} (RunPod: ${runpodJobId})`);

        // Start background processing (don't await it)
        processMultiTalkJob(job.id, runpodJobId).catch(error => {
            console.error(`‚ùå Background processing error for job ${job.id}:`, error);
        });

        return NextResponse.json({
            jobId: job.id,
            runpodJobId,
            status: 'processing',
        });

    } catch (error) {
        console.error('‚ùå MultiTalk generation error:', error);
        return NextResponse.json(
            { error: `MultiTalk generation failed: ${error}` },
            { status: 500 }
        );
    }
}

// Background processing function
async function processMultiTalkJob(jobId: string, runpodJobId: string) {
    try {
        console.log(`üîÑ Starting background processing for job ${jobId}`);
        
        // Get job details to find user ID
        const job = await prisma.job.findUnique({
            where: { id: jobId }
        });
        
        if (!job) {
            throw new Error(`Job ${jobId} not found`);
        }
        
        // Load user settings for background processing
        const { settings } = await settingsService.getSettings(job.userId);
        
        if (!settings.runpod || typeof settings.runpod === 'string' || typeof settings.runpod === 'number' || 
            !(settings.runpod as any).apiKey || !(settings.runpod as any).endpoints?.multitalk) {
            throw new Error('RunPod configuration missing for background processing');
        }
        
        const runpodSettings = settings.runpod as any;

        const runpodService = new RunPodService(
            runpodSettings.apiKey,
            runpodSettings.endpoints.multitalk
        );

        // Wait for RunPod job completion
        const result = await runpodService.waitForCompletion(runpodJobId);

        if (result.status === 'COMPLETED' && result.output) {
            console.log(`‚úÖ RunPod job completed: ${runpodJobId}`);
            console.log('üé¨ RunPod output structure:', JSON.stringify(result.output, null, 2));
            console.log('üé¨ Available output keys:', Object.keys(result.output));
            
            // Í∞Å ÌïÑÎìúÏùò ÌÉÄÏûÖÍ≥º ÎÇ¥Ïö© ÌôïÏù∏
            Object.entries(result.output).forEach(([key, value]) => {
                if (value) {
                    console.log(`üîç Field: ${key}, Type: ${typeof value}, Length: ${typeof value === 'string' ? value.length : 'N/A'}`);
                    if (typeof value === 'string' && value.length > 100) {
                        console.log(`üîç ${key} preview: ${value.substring(0, 100)}...`);
                    }
                }
            });

            // Handle the result
            let resultUrl = null;
            let runpodResultUrl = null;

            if (result.output.video_base64) {
                // Base64 ÎπÑÎîîÏò§ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäî Í≤ΩÏö∞
                console.log('üìπ Video base64 data received from RunPod');
                console.log('üìπ Base64 length:', result.output.video_base64.length, 'characters');
                
                // Base64Î•º ÎîîÏΩîÎî©ÌïòÏó¨ Î°úÏª¨Ïóê Ï†ÄÏû•
                try {
                    const videoBuffer = Buffer.from(result.output.video_base64, 'base64');
                    console.log('üìπ Decoded video buffer size:', videoBuffer.length);
                    
                    const outputDir = join(LOCAL_STORAGE_DIR, `output_${jobId}`);
                    mkdirSync(outputDir, { recursive: true });

                    const outputFilePath = join(outputDir, `multitalk_result_${jobId}.mp4`);
                    writeFileSync(outputFilePath, videoBuffer);
                    console.log('‚úÖ Video saved locally:', outputFilePath);
                    
                    // ÏõπÏóêÏÑú Ï†ëÍ∑º Í∞ÄÎä•Ìïú Í≤ΩÎ°ú ÏÑ§Ï†ï
                    resultUrl = `/results/output_${jobId}/multitalk_result_${jobId}.mp4`;
                    runpodResultUrl = outputFilePath;
                    
                } catch (saveError) {
                    console.error('‚ùå Failed to save video locally:', saveError);
                    resultUrl = `/api/results/${jobId}.mp4`;
                    runpodResultUrl = result.output.video_base64;
                }
                
            } else if (result.output.video_url) {
                // RunPodÏóêÏÑú ÏßÅÏ†ë ÎπÑÎîîÏò§ URLÏùÑ Ï†úÍ≥µÌïòÎäî Í≤ΩÏö∞
                console.log('üîó Direct video URL from RunPod:', result.output.video_url);
                resultUrl = result.output.video_url;
                runpodResultUrl = result.output.video_url;
                
            } else if (result.output.output_url) {
                // ÏùºÎ∞òÏ†ÅÏù∏ output_url ÌïÑÎìú
                console.log('üîó Output URL from RunPod:', result.output.output_url);
                resultUrl = result.output.output_url;
                runpodResultUrl = result.output.output_url;
                
            } else if (result.output.video_path || result.output.file_path) {
                // RunPod ÎÇ¥Î∂Ä ÌååÏùº Í≤ΩÎ°ú
                const filePath = result.output.video_path || result.output.file_path;
                console.log('üìÅ File path from RunPod:', filePath);
                
                // RunPod APIÎ•º ÌÜµÌï¥ ÌååÏùºÏùÑ Îã§Ïö¥Î°úÎìúÌïòÍ≥† Î°úÏª¨Ïóê Ï†ÄÏû•
                try {
                    console.log('üì• Downloading file from RunPod...');
                    
                    // RunPod APIÎ•º ÌÜµÌï¥ ÌååÏùº Îã§Ïö¥Î°úÎìú (Í∏∞Î≥∏ URL ÏÇ¨Ïö©)
                    const downloadResponse = await fetch(`https://api.runpod.io/v2/${runpodJobId}/stream`, {
                        headers: {
                            'Authorization': `Bearer ${runpodSettings.apiKey}`,
                        },
                    });
                    
                    if (downloadResponse.ok) {
                        const fileBuffer = await downloadResponse.arrayBuffer();
                        console.log('üì• Downloaded file size:', fileBuffer.byteLength);
                        
                        const outputDir = join(LOCAL_STORAGE_DIR, `output_${jobId}`);
                        mkdirSync(outputDir, { recursive: true });

                        const outputFilePath = join(outputDir, `multitalk_result_${jobId}.mp4`);
                        writeFileSync(outputFilePath, Buffer.from(fileBuffer));
                        console.log('‚úÖ File saved locally:', outputFilePath);
                        
                        // ÏõπÏóêÏÑú Ï†ëÍ∑º Í∞ÄÎä•Ìïú Í≤ΩÎ°ú ÏÑ§Ï†ï
                        resultUrl = `/results/output_${jobId}/multitalk_result_${jobId}.mp4`;
                        runpodResultUrl = outputFilePath;
                        
                    } else {
                        console.warn('‚ö†Ô∏è Failed to download file from RunPod, using fallback');
                        resultUrl = `/api/results/${jobId}.mp4`;
                        runpodResultUrl = filePath;
                    }
                    
                } catch (downloadError) {
                    console.error('‚ùå Failed to download file from RunPod:', downloadError);
                    resultUrl = `/api/results/${jobId}.mp4`;
                    runpodResultUrl = filePath;
                }
                
            } else {
                console.warn('‚ö†Ô∏è No video data found in RunPod output');
                console.log('üîç Checking for alternative video fields...');
                
                // Ï∂îÍ∞ÄÏ†ÅÏù∏ ÎπÑÎîîÏò§ Í¥ÄÎ†® ÌïÑÎìú ÌôïÏù∏
                const videoFields = ['video', 'mp4', 'avi', 'mov', 'result', 'output', 'file'];
                for (const field of videoFields) {
                    if (result.output[field]) {
                        console.log(`üîç Found potential video field: ${field} =`, result.output[field]);
                    }
                }
                
                // Ìè¥Î∞±: Í∏∞Î≥∏ Í≤ΩÎ°ú ÏÑ§Ï†ï
                resultUrl = `/api/results/${jobId}.mp4`;
                runpodResultUrl = 'unknown';
            }

            // Update job status to completed with result URL
            await prisma.job.update({
                where: { id: jobId },
                data: {
                    status: 'completed',
                    resultUrl,
                    completedAt: new Date(),
                    options: JSON.stringify({
                        ...JSON.parse(job.options || '{}'),
                        runpodResultUrl,
                        runpodOutput: Object.keys(result.output || {}).reduce((acc: any, key: string) => {
                            const value = result.output[key];
                            if (typeof value === 'string' && value.length > 1000) {
                                acc[key] = `${value.substring(0, 100)}... (${value.length} characters)`;
                            } else {
                                acc[key] = value;
                            }
                            return acc;
                        }, {}),
                        completedAt: new Date().toISOString()
                    })
                },
            });

            console.log(`‚úÖ Job ${jobId} marked as completed with result URL: ${resultUrl}`);
            console.log(`‚úÖ RunPod result URL: ${runpodResultUrl}`);

        } else {
            console.error('‚ùå RunPod job failed or no output');
            console.error('Status:', result.status);
            console.error('Error:', result.error);
            console.error('Output:', result.output);
            throw new Error(`RunPod job failed: ${result.error}`);
        }

    } catch (error) {
        console.error(`‚ùå Background processing failed for job ${jobId}:`, error);

        // Update job status to failed
        await prisma.job.update({
            where: { id: jobId },
            data: {
                status: 'failed',
                completedAt: new Date(),
            },
        });
    }
}