// src/app/api/multitalk/route.ts

import { NextRequest, NextResponse } from 'next/server';
import { PrismaClient } from '@prisma/client';
import RunPodService from '@/lib/runpodService';
import SettingsService from '@/lib/settingsService';
import S3Service from '@/lib/s3Service';
import { writeFileSync, mkdirSync } from 'fs';
import { join } from 'path';

const prisma = new PrismaClient();
const settingsService = new SettingsService();

// ë¡œì»¬ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
const LOCAL_STORAGE_DIR = join(process.cwd(), 'public', 'results');

// ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
try {
    mkdirSync(LOCAL_STORAGE_DIR, { recursive: true });
} catch (error) {
    console.log('ğŸ“ Results directory already exists or cannot be created');
}

export async function POST(request: NextRequest) {
    try {
        console.log('ğŸ­ Processing MultiTalk generation request...');

        const formData = await request.formData();

        // Extract form data
        const userId = formData.get('userId') as string;
        const audioMode = formData.get('audioMode') as string;
        const prompt = formData.get('prompt') as string || 'a person talking';
        
        console.log('ğŸ“‹ FormData extracted values:');
        console.log('  - userId:', userId);
        console.log('  - audioMode:', audioMode, '(type:', typeof audioMode, ')');
        console.log('  - prompt:', prompt);
        
        // Load user settings
        console.log('ğŸ“– Loading user settings...');
        const { settings } = await settingsService.getSettings(userId);

        // Get current workspace ID
        const currentWorkspaceId = await settingsService.getCurrentWorkspaceId(userId);
        
        // Validate RunPod configuration
        if (!settings.runpod || typeof settings.runpod === 'string' || typeof settings.runpod === 'number' || 
            !(settings.runpod as any).apiKey || !(settings.runpod as any).endpoints?.multitalk) {
            return NextResponse.json({
                error: 'RunPod configuration incomplete. Please configure your API key and MultiTalk endpoint in Settings.',
                requiresSetup: true,
            }, { status: 400 });
        }
        
        // Type assertion for settings
        const runpodSettings = settings.runpod as any;

        const imageFile = formData.get('image') as File;
        const audio1File = formData.get('audio1') as File;
        const audio2File = formData.get('audio2') as File | null;

        // Validate required files
        if (!imageFile || !audio1File) {
            return NextResponse.json(
                { error: 'Image and at least one audio file are required' },
                { status: 400 }
            );
        }

        if (audioMode === 'dual' && !audio2File) {
            return NextResponse.json(
                { error: 'Second audio file is required for dual mode' },
                { status: 400 }
            );
        }

        // ë¡œì»¬ íŒŒì¼ ì •ë³´ ì €ì¥ (ì¸ë„¤ì¼ìš©)
        const localFileInfo = {
            image: {
                name: imageFile.name,
                size: imageFile.size,
                type: imageFile.type,
                lastModified: imageFile.lastModified
            },
            audio1: {
                name: audio1File.name,
                size: audio1File.size,
                type: audio1File.type,
                lastModified: audio1File.lastModified
            },
            ...(audio2File && {
                audio2: {
                    name: audio2File.name,
                    size: audio2File.size,
                    type: audio2File.type,
                    lastModified: audio2File.lastModified
                }
            })
        };

        console.log('ğŸ“ Local file info:', localFileInfo);

        // Create job record in database
        const job = await prisma.job.create({
            data: {
                id: Math.random().toString(36).substring(2, 15),
                userId,
                workspaceId: currentWorkspaceId,
                status: 'processing',
                type: 'multitalk',
                prompt,
                options: JSON.stringify({ audioMode }),
                createdAt: new Date(),
            },
        });

        console.log(`ğŸ“ Created job record: ${job.id}`);

        // Deduct credit
        await prisma.creditActivity.create({
            data: {
                userId,
                activity: `Generated MultiTalk content (Job ID: ${job.id})`,
                amount: -2, // MultiTalk costs more credits
            },
        });

        // íŒŒì¼ë“¤ì„ S3ì— ì—…ë¡œë“œ
        console.log('ğŸ“¤ Uploading files to S3...');
        const s3Service = new S3Service();
        
        const imageBuffer = Buffer.from(await imageFile.arrayBuffer());
        const audio1Buffer = Buffer.from(await audio1File.arrayBuffer());
        
        // ì´ë¯¸ì§€ íŒŒì¼ S3 ì—…ë¡œë“œ
        const imageUpload = await s3Service.uploadFile(imageBuffer, imageFile.name, imageFile.type);
        console.log('âœ… Image uploaded to S3:', imageUpload);
        
        // ì˜¤ë””ì˜¤1 íŒŒì¼ S3 ì—…ë¡œë“œ
        const audio1Upload = await s3Service.uploadFile(audio1Buffer, audio1File.name, audio1File.type);
        console.log('âœ… Audio1 uploaded to S3:', audio1Upload);
        
        let audio2Upload: { s3Url: string; filePath: string } | undefined;
        if (audio2File) {
            const audio2Buffer = Buffer.from(await audio2File.arrayBuffer());
            audio2Upload = await s3Service.uploadFile(audio2Buffer, audio2File.name, audio2File.type);
            console.log('âœ… Audio2 uploaded to S3:', audio2Upload);
        }

        // íŒŒì¼ë“¤ì„ ë¡œì»¬ì—ë„ ì €ì¥ (ë°±ì—…ìš©)
        const imagePath = join(LOCAL_STORAGE_DIR, `input_${job.id}_${imageFile.name}`);
        const audio1Path = join(LOCAL_STORAGE_DIR, `input_${job.id}_${audio1File.name}`);
        
        let audio2Path: string | undefined;
        if (audio2File) {
            audio2Path = join(LOCAL_STORAGE_DIR, `input_${job.id}_${audio2File.name}`);
            
            try {
                const audio2Buffer = Buffer.from(await audio2File.arrayBuffer());
                writeFileSync(audio2Path, audio2Buffer);
                console.log('âœ… Audio2 saved locally:', audio2Path);
            } catch (saveError) {
                console.error('âŒ Failed to save audio2 locally:', saveError);
                // S3 ì—…ë¡œë“œëŠ” ì„±ê³µí–ˆìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰
            }
        }

        try {
            writeFileSync(imagePath, imageBuffer);
            writeFileSync(audio1Path, audio1Buffer);
            console.log('âœ… Files saved locally (backup):', { imagePath, audio1Path });
        } catch (saveError) {
            console.error('âŒ Failed to save files locally (backup):', saveError);
            // S3 ì—…ë¡œë“œëŠ” ì„±ê³µí–ˆìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰
        }

        // Prepare RunPod input - S3 ê²½ë¡œ ì‚¬ìš©
        console.log('ğŸ”§ Preparing RunPod input...');
        console.log('  - audioMode:', audioMode);
        console.log('  - audio2File exists:', !!audio2File);
        console.log('  - audio2Upload exists:', !!audio2Upload);
        console.log('  - Will set audio_type to "para":', audioMode === 'dual');
        
        // S3 ê²½ë¡œ ì‚¬ìš© (runpod-volume í˜•ì‹)
        const runpodInput = {
            prompt: prompt || "a man talking",
            image_path: imageUpload.filePath, // S3 ê²½ë¡œ (/runpod-volume/...)
            audio_paths: {
                person1: audio1Upload.filePath, // S3 ê²½ë¡œ (/runpod-volume/...)
                ...(audioMode === 'dual' && audio2Upload && { person2: audio2Upload.filePath }), // ë“€ì–¼ ëª¨ë“œì¼ ë•Œë§Œ person2 ì¶”ê°€
            },
        };

        // ë“€ì–¼ ì˜¤ë””ì˜¤ ëª¨ë“œì¼ ë•Œ audio_typeì„ paraë¡œ ì„¤ì •
        if (audioMode === 'dual') {
            (runpodInput as any).audio_type = 'para';
            console.log('âœ… audio_type set to "para" for dual mode');
        }

        console.log('ğŸ”§ Final RunPod input structure (S3 paths):');
        console.log('  - prompt:', runpodInput.prompt);
        console.log('  - image_path:', runpodInput.image_path);
        console.log('  - audio_paths:', runpodInput.audio_paths);
        console.log('  - audioMode:', audioMode);
        console.log('  - audio2File exists:', !!audio2File);
        console.log('  - audio2Upload exists:', !!audio2Upload);
        console.log('  - audio_type:', (runpodInput as any).audio_type);
        console.log('  - Full RunPod input:', JSON.stringify(runpodInput, null, 2));

        console.log('ğŸš€ Submitting job to RunPod...', runpodInput);

        // Submit job to RunPod using user settings
        let runpodJobId: string;
        try {
            console.log('ğŸ”§ Creating RunPod service with user settings...');
            const runpodService = new RunPodService(
                runpodSettings.apiKey,
                runpodSettings.endpoints.multitalk,
                runpodSettings.generateTimeout || 3600 // Generate íƒ€ì„ì•„ì›ƒ ì„¤ì • ì „ë‹¬
            );

            console.log('ğŸ”§ Submitting to RunPod with input:', JSON.stringify(runpodInput, null, 2));
            runpodJobId = await runpodService.submitJob(runpodInput);

            console.log(`âœ… RunPod job submitted successfully: ${runpodJobId}`);
        } catch (runpodError) {
            console.error('âŒ RunPod submission failed:', runpodError);

            // Update job status to failed
            await prisma.job.update({
                where: { id: job.id },
                data: {
                    status: 'failed',
                    completedAt: new Date(),
                },
            });

            return NextResponse.json({
                error: `RunPod submission failed: ${runpodError}`,
                jobId: job.id,
                status: 'failed',
            }, { status: 500 });
        }

        // Update job with RunPod job ID and S3 paths
        await prisma.job.update({
            where: { id: job.id },
            data: {
                options: JSON.stringify({
                    audioMode,
                    runpodJobId,
                    // S3 ì—…ë¡œë“œ ì •ë³´
                    imageS3Url: imageUpload.s3Url,
                    imageS3Path: imageUpload.filePath,
                    audio1S3Url: audio1Upload.s3Url,
                    audio1S3Path: audio1Upload.filePath,
                    ...(audio2Upload && {
                        audio2S3Url: audio2Upload.s3Url,
                        audio2S3Path: audio2Upload.filePath,
                    }),
                    // ë¡œì»¬ íŒŒì¼ ê²½ë¡œë“¤ (ë°±ì—…ìš©)
                    imagePath,
                    audio1Path,
                    audio2Path,
                    // ë¡œì»¬ ì´ë¯¸ì§€ ì›¹ ê²½ë¡œ (ì´ë¯¸ì§€ í‘œì‹œìš©)
                    imageWebPath: `/results/input_${job.id}_${imageFile.name}`,
                    // ë¡œì»¬ íŒŒì¼ ì •ë³´
                    localFileInfo,
                }),
            },
        });

        console.log(`âœ… MultiTalk job submitted: ${job.id} (RunPod: ${runpodJobId})`);

        // Start background processing (don't await it)
        processMultiTalkJob(job.id, runpodJobId).catch(error => {
            console.error(`âŒ Background processing error for job ${job.id}:`, error);
        });

        return NextResponse.json({
            jobId: job.id,
            runpodJobId,
            status: 'processing',
        });

    } catch (error) {
        console.error('âŒ MultiTalk generation error:', error);
        return NextResponse.json(
            { error: `MultiTalk generation failed: ${error}` },
            { status: 500 }
        );
    }
}

// Background processing function
async function processMultiTalkJob(jobId: string, runpodJobId: string) {
    try {
        console.log(`ğŸ”„ Starting background processing for job ${jobId}`);
        
        // Get job details to find user ID
        const job = await prisma.job.findUnique({
            where: { id: jobId }
        });
        
        if (!job) {
            throw new Error(`Job ${jobId} not found`);
        }
        
        // Load user settings for background processing
        const { settings } = await settingsService.getSettings(job.userId);
        
        if (!settings.runpod || typeof settings.runpod === 'string' || typeof settings.runpod === 'number' || 
            !(settings.runpod as any).apiKey || !(settings.runpod as any).endpoints?.multitalk) {
            throw new Error('RunPod configuration missing for background processing');
        }
        
        const runpodSettings = settings.runpod as any;

        const runpodService = new RunPodService(
            runpodSettings.apiKey,
            runpodSettings.endpoints.multitalk
        );

        // Wait for RunPod job completion
        const result = await runpodService.waitForCompletion(runpodJobId);

        if (result.status === 'COMPLETED' && result.output) {
            console.log(`âœ… RunPod job completed: ${runpodJobId}`);
            console.log('ğŸ¬ RunPod output structure:', JSON.stringify(result.output, null, 2));
            console.log('ğŸ¬ Available output keys:', Object.keys(result.output));
            
            // ê° í•„ë“œì˜ íƒ€ì…ê³¼ ë‚´ìš© í™•ì¸
            Object.entries(result.output).forEach(([key, value]) => {
                if (value) {
                    console.log(`ğŸ” Field: ${key}, Type: ${typeof value}, Length: ${typeof value === 'string' ? value.length : 'N/A'}`);
                    if (typeof value === 'string' && value.length > 100) {
                        console.log(`ğŸ” ${key} preview: ${value.substring(0, 100)}...`);
                    }
                }
            });

            // Handle the result
            let resultUrl = null;
            let runpodResultUrl = null;

            if (result.output.video_base64) {
                // Base64 ë¹„ë””ì˜¤ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
                console.log('ğŸ“¹ Video base64 data received from RunPod');
                console.log('ğŸ“¹ Base64 length:', result.output.video_base64.length, 'characters');
                
                // Base64ë¥¼ ë””ì½”ë”©í•˜ì—¬ ë¡œì»¬ì— ì €ì¥
                try {
                    const videoBuffer = Buffer.from(result.output.video_base64, 'base64');
                    console.log('ğŸ“¹ Decoded video buffer size:', videoBuffer.length);
                    
                    const outputDir = join(LOCAL_STORAGE_DIR, `output_${jobId}`);
                    mkdirSync(outputDir, { recursive: true });

                    const outputFilePath = join(outputDir, `multitalk_result_${jobId}.mp4`);
                    writeFileSync(outputFilePath, videoBuffer);
                    console.log('âœ… Video saved locally:', outputFilePath);
                    
                    // ì›¹ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ê²½ë¡œ ì„¤ì •
                    resultUrl = `/results/output_${jobId}/multitalk_result_${jobId}.mp4`;
                    runpodResultUrl = outputFilePath;
                    
                } catch (saveError) {
                    console.error('âŒ Failed to save video locally:', saveError);
                    resultUrl = `/api/results/${jobId}.mp4`;
                    runpodResultUrl = result.output.video_base64;
                }
                
            } else if (result.output.video_url) {
                // RunPodì—ì„œ ì§ì ‘ ë¹„ë””ì˜¤ URLì„ ì œê³µí•˜ëŠ” ê²½ìš°
                console.log('ğŸ”— Direct video URL from RunPod:', result.output.video_url);
                resultUrl = result.output.video_url;
                runpodResultUrl = result.output.video_url;
                
            } else if (result.output.output_url) {
                // ì¼ë°˜ì ì¸ output_url í•„ë“œ
                console.log('ğŸ”— Output URL from RunPod:', result.output.output_url);
                resultUrl = result.output.output_url;
                runpodResultUrl = result.output.output_url;
                
            } else if (result.output.video_path || result.output.file_path) {
                // RunPod ë‚´ë¶€ íŒŒì¼ ê²½ë¡œ
                const filePath = result.output.video_path || result.output.file_path;
                console.log('ğŸ“ File path from RunPod:', filePath);
                
                // RunPod APIë¥¼ í†µí•´ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¡œì»¬ì— ì €ì¥
                try {
                    console.log('ğŸ“¥ Downloading file from RunPod...');
                    
                    // RunPod APIë¥¼ í†µí•´ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ê¸°ë³¸ URL ì‚¬ìš©)
                    const downloadResponse = await fetch(`https://api.runpod.io/v2/${runpodJobId}/stream`, {
                        headers: {
                            'Authorization': `Bearer ${runpodSettings.apiKey}`,
                        },
                    });
                    
                    if (downloadResponse.ok) {
                        const fileBuffer = await downloadResponse.arrayBuffer();
                        console.log('ğŸ“¥ Downloaded file size:', fileBuffer.byteLength);
                        
                        const outputDir = join(LOCAL_STORAGE_DIR, `output_${jobId}`);
                        mkdirSync(outputDir, { recursive: true });

                        const outputFilePath = join(outputDir, `multitalk_result_${jobId}.mp4`);
                        writeFileSync(outputFilePath, Buffer.from(fileBuffer));
                        console.log('âœ… File saved locally:', outputFilePath);
                        
                        // ì›¹ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ê²½ë¡œ ì„¤ì •
                        resultUrl = `/results/output_${jobId}/multitalk_result_${jobId}.mp4`;
                        runpodResultUrl = outputFilePath;
                        
                    } else {
                        console.warn('âš ï¸ Failed to download file from RunPod, using fallback');
                        resultUrl = `/api/results/${jobId}.mp4`;
                        runpodResultUrl = filePath;
                    }
                    
                } catch (downloadError) {
                    console.error('âŒ Failed to download file from RunPod:', downloadError);
                    resultUrl = `/api/results/${jobId}.mp4`;
                    runpodResultUrl = filePath;
                }
                
            } else {
                console.warn('âš ï¸ No video data found in RunPod output');
                console.log('ğŸ” Checking for alternative video fields...');
                
                // ì¶”ê°€ì ì¸ ë¹„ë””ì˜¤ ê´€ë ¨ í•„ë“œ í™•ì¸
                const videoFields = ['video', 'mp4', 'avi', 'mov', 'result', 'output', 'file'];
                for (const field of videoFields) {
                    if (result.output[field]) {
                        console.log(`ğŸ” Found potential video field: ${field} =`, result.output[field]);
                    }
                }
                
                // í´ë°±: ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
                resultUrl = `/api/results/${jobId}.mp4`;
                runpodResultUrl = 'unknown';
            }

            // Update job status to completed with result URL
            await prisma.job.update({
                where: { id: jobId },
                data: {
                    status: 'completed',
                    resultUrl,
                    completedAt: new Date(),
                    options: JSON.stringify({
                        ...JSON.parse(job.options || '{}'),
                        runpodResultUrl,
                        runpodOutput: result.output,
                        completedAt: new Date().toISOString()
                    })
                },
            });

            console.log(`âœ… Job ${jobId} marked as completed with result URL: ${resultUrl}`);
            console.log(`âœ… RunPod result URL: ${runpodResultUrl}`);

        } else {
            console.error('âŒ RunPod job failed or no output');
            console.error('Status:', result.status);
            console.error('Error:', result.error);
            console.error('Output:', result.output);
            throw new Error(`RunPod job failed: ${result.error}`);
        }

    } catch (error) {
        console.error(`âŒ Background processing failed for job ${jobId}:`, error);

        // Update job status to failed
        await prisma.job.update({
            where: { id: jobId },
            data: {
                status: 'failed',
                completedAt: new Date(),
            },
        });
    }
}