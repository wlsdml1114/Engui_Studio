// src/lib/runpodService.ts

interface RunPodJobResponse {
  id: string;
  status: 'IN_QUEUE' | 'IN_PROGRESS' | 'COMPLETED' | 'FAILED';
  output?: any;
  error?: string;
}

interface MultiTalkInput {
  prompt?: string;
  image_path: string;
  audio_paths: {
    person1: string;
    person2?: string;
  };
  audio_type?: string; // ë“€ì–¼ ì˜¤ë””ì˜¤ ëª¨ë“œìš© audio_type
}

interface FluxKontextInput {
  prompt: string;
  image_path: string;
  width: number;
  height: number;
  seed?: number;
  guidance: number; // cfgë¥¼ guidanceë¡œ ë³€ê²½
}

interface FluxKreaInput {
  prompt: string;
  width: number;
  height: number;
  seed: number;
  guidance: number;
  model?: string;
  lora?: Array<[string, number]>; // [["filename.safetensors", weight]] í˜•íƒœ
}

interface Wan22Input {
  prompt: string;
  image_path: string; // base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„° (í‚¤ëŠ” image_path)
  end_image_path?: string; // optional end frame image
  width: number;
  height: number;
  seed: number;
  cfg: number;
  length: number;
  steps: number; // stepì„ stepsë¡œ ë³€ê²½
  context_overlap?: number; // context overlap ì¶”ê°€
  lora_pairs?: Array<{
    high: string;
    low: string;
    high_weight: number;
    low_weight: number;
  }>;
}

interface WanAnimateInput {
  prompt: string;
  image_path?: string;
  video_path?: string;
  positive_prompt: string;
  seed: number;
  cfg: number;
  steps: number;
  width: number;
  height: number;
  fps?: number;
  mode?: string;
  points_store?: {
    positive: Array<{x: number, y: number}>;
    negative: Array<{x: number, y: number}>;
  };
  coordinates?: Array<{x: number, y: number}>;
  neg_coordinates?: Array<{x: number, y: number}>;
}

interface InfiniteTalkInput {
  prompt: string;
  input_type: string; // "image" ë˜ëŠ” "video"
  person_count: string; // "single" ë˜ëŠ” "multi"
  image_path?: string; // S3 ê²½ë¡œ ë˜ëŠ” ë¡œì»¬ ê²½ë¡œ (image íƒ€ì…ì¼ ë•Œ)
  video_path?: string; // S3 ê²½ë¡œ ë˜ëŠ” ë¡œì»¬ ê²½ë¡œ (video íƒ€ì…ì¼ ë•Œ)
  wav_path: string; // S3 ê²½ë¡œ ë˜ëŠ” ë¡œì»¬ ê²½ë¡œ
  wav_path_2?: string; // ë‹¤ì¤‘ ì¸ë¬¼ìš© ë‘ ë²ˆì§¸ ì˜¤ë””ì˜¤ (multiì¼ ë•Œ)
  width: number;
  height: number;
  network_volume?: boolean;
}

interface VideoUpscaleInput {
  task_type: string; // "upscale" ë˜ëŠ” "upscale_and_interpolation"
  video_path: string; // S3 ê²½ë¡œ
}

interface QwenImageEditInput {
  prompt: string;
  image_base64: string; // base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„°
  image_base64_2?: string; // optional second image
  seed: number;
  width: number;
  height: number;
  steps?: number;
  guidance_scale: number;
}

type RunPodInput = MultiTalkInput | FluxKontextInput | FluxKreaInput | Wan22Input | WanAnimateInput | InfiniteTalkInput | VideoUpscaleInput | QwenImageEditInput;

class RunPodService {
  private apiKey: string;
  private endpointId: string;
  private baseUrl: string;
  private generateTimeout: number; // AI ìƒì„± ì‘ì—… íƒ€ì„ì•„ì›ƒ (ë°€ë¦¬ì´ˆ)

  constructor(apiKey?: string, endpointId?: string, generateTimeout?: number) {
    // Use provided credentials or fall back to environment variables
    this.apiKey = apiKey || process.env.RUNPOD_API_KEY!;
    this.endpointId = endpointId || process.env.RUNPOD_ENDPOINT_ID!;
    this.baseUrl = `https://api.runpod.ai/v2/${this.endpointId}`;
    this.generateTimeout = (generateTimeout || 3600) * 1000; // ì´ˆë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
    
    if (!this.apiKey || !this.endpointId) {
      throw new Error('RunPod API key and endpoint ID are required');
    }
  }

  private getHeaders() {
    return {
      'Authorization': `Bearer ${this.apiKey}`,
      'Content-Type': 'application/json',
    };
  }

  async submitJob(input: RunPodInput): Promise<string> {
    console.log('ğŸš€ Submitting job to RunPod...');
    console.log('ğŸ“‹ Endpoint ID:', this.endpointId);

    // Match the Python code structure exactly
    let payload: any;
    if ('audio_paths' in input) {
      // MultiTalk input
      payload = {
        input: {
          prompt: input.prompt || "a man talking",
          image_path: input.image_path,
          audio_paths: input.audio_paths,
          ...(input.audio_type && { audio_type: input.audio_type }) // audio_typeì´ ìˆìœ¼ë©´ í¬í•¨
        }
      };

      console.log('ğŸ­ MultiTalk payload created:');
      console.log('  - prompt:', payload.input.prompt);
      console.log('  - image_path:', payload.input.image_path);
      console.log('  - audio_paths:', payload.input.audio_paths);
      console.log('  - audio_type:', payload.input.audio_type || 'not set');
    } else if ('guidance' in input && 'image_path' in input) {
      // FluxKontext input
      payload = {
        input: {
          prompt: input.prompt,
          image_path: input.image_path,
          width: input.width,
          height: input.height,
          seed: input.seed,
          guidance: input.guidance
        }
      };

      console.log('ğŸ­ FluxKontext payload created:');
      console.log('  - prompt:', payload.input.prompt);
      console.log('  - image_path:', payload.input.image_path);
      console.log('  - width:', payload.input.width);
      console.log('  - height:', payload.input.height);
      console.log('  - seed:', payload.input.seed);
      console.log('  - guidance:', payload.input.guidance);
    } else if ('guidance' in input && !('image_path' in input)) {
      // FluxKrea input
      payload = {
        input: {
          prompt: input.prompt,
          width: input.width,
          height: input.height,
          seed: input.seed,
          guidance: input.guidance,
          ...(input.model && { model: input.model }),
          ...(input.lora && { lora: input.lora })
        }
      };

      console.log('ğŸ­ FluxKrea payload created:');
      console.log('  - prompt:', payload.input.prompt);
      console.log('  - width:', payload.input.width);
      console.log('  - height:', payload.input.height);
      console.log('  - seed:', payload.input.seed);
      console.log('  - guidance:', payload.input.guidance);
      if (payload.input.model) {
        console.log('  - model:', payload.input.model);
      }
      if (payload.input.lora) {
        console.log('  - lora:', payload.input.lora);
        console.log('  - lora count:', payload.input.lora.length);
      }
    } else if ('cfg' in input && ('video_path' in input || 'positive_prompt' in input)) {
      // WanAnimate input
      payload = {
        input: {
          prompt: input.prompt,
          positive_prompt: input.positive_prompt,
          seed: input.seed,
          cfg: input.cfg,
          steps: input.steps,
          width: input.width,
          height: input.height,
          ...(input.fps && { fps: input.fps }),
          ...(input.mode && { mode: input.mode }),
          points_store: input.points_store,
          coordinates: input.coordinates,
          neg_coordinates: input.neg_coordinates,
          ...(input.image_path && { image_path: input.image_path }),
          ...(input.video_path && { video_path: input.video_path })
        }
      };

      console.log('ğŸ­ WanAnimate payload created:', {
        prompt: payload.input.prompt,
        seed: payload.input.seed,
        cfg: payload.input.cfg,
        steps: payload.input.steps,
        width: payload.input.width,
        height: payload.input.height,
        fps: payload.input.fps || 'not set',
        mode: payload.input.mode || 'not set',
        ...(payload.input.points_store && { points_store: 'âœ“ set' }),
        ...(payload.input.coordinates && { coordinates: 'âœ“ set' }),
        ...(payload.input.neg_coordinates && { neg_coordinates: 'âœ“ set' })
      });
    } else if ('cfg' in input && !('video_path' in input) && !('positive_prompt' in input)) {
      // Wan22 input
      payload = {
        input: {
          prompt: input.prompt,
          image_path: input.image_path,
          width: input.width,
          height: input.height,
          seed: input.seed,
          cfg: input.cfg,
          length: input.length,
          steps: input.steps, // stepsë¡œ ë³€ê²½
          context_overlap: input.context_overlap, // context overlap ì¶”ê°€
          ...(input.end_image_path && { end_image_path: input.end_image_path }), // end_image_path ì¶”ê°€
          ...(input.lora_pairs && { lora_pairs: input.lora_pairs }) // LoRA pairs ì¶”ê°€
        }
      };

      console.log('ğŸ­ Wan22 payload created:');
      console.log('  - prompt:', payload.input.prompt);
      console.log('  - image_path:', `[base64 data] (${payload.input.image_path.length} characters)`);
      console.log('  - end_image_path:', payload.input.end_image_path || 'not set');
      console.log('  - width:', payload.input.width);
      console.log('  - height:', payload.input.height);
      console.log('  - seed:', payload.input.seed);
      console.log('  - cfg:', payload.input.cfg);
      console.log('  - length:', payload.input.length);
      console.log('  - steps:', payload.input.steps);
      console.log('  - context_overlap:', payload.input.context_overlap || 'not set');
      if (payload.input.lora_pairs) {
        console.log('  - lora_pairs:', payload.input.lora_pairs);
      }
    } else if ('wav_path' in input) {
      // InfiniteTalk input
      payload = {
        input: {
          prompt: input.prompt,
          input_type: input.input_type,
          person_count: input.person_count,
          ...(input.image_path && { image_path: input.image_path }),
          ...(input.video_path && { video_path: input.video_path }),
          wav_path: input.wav_path,
          ...(input.wav_path_2 && { wav_path_2: input.wav_path_2 }),
          width: input.width,
          height: input.height,
          ...(input.network_volume && { network_volume: true })
        }
      };

      console.log('ğŸ­ InfiniteTalk payload created:');
      console.log('  - prompt:', payload.input.prompt);
      console.log('  - input_type:', payload.input.input_type);
      console.log('  - person_count:', payload.input.person_count);
      console.log('  - image_path:', payload.input.image_path || 'not set');
      console.log('  - video_path:', payload.input.video_path || 'not set');
      console.log('  - wav_path:', payload.input.wav_path);
      console.log('  - wav_path_2:', payload.input.wav_path_2 || 'not set');
      console.log('  - width:', payload.input.width);
      console.log('  - height:', payload.input.height);
    } else if ('task_type' in input && 'video_path' in input) {
      // Video Upscale input
      payload = {
        input: {
          video_path: input.video_path,
          task_type: input.task_type,
          network_volume: true
        }
      };

      console.log('ğŸ¬ Video Upscale payload created:');
      console.log('  - video_path:', payload.input.video_path);
      console.log('  - task_type:', payload.input.task_type);
      console.log('  - network_volume:', payload.input.network_volume);
    } else if ('guidance_scale' in input && 'image_base64' in input && 'width' in input) {
      // Qwen Image Edit input
      payload = {
        input: {
          prompt: input.prompt,
          image_base64: input.image_base64,
          ...(input.image_base64_2 && { image_base64_2: input.image_base64_2 }),
          seed: input.seed,
          width: input.width,
          height: input.height,
          ...(input.steps && { steps: input.steps }),
          guidance_scale: input.guidance_scale
        }
      };

      console.log('ğŸ¨ Qwen Image Edit payload created:');
      console.log('  - prompt:', payload.input.prompt);
      console.log('  - image_base64:', `[base64 data] (${payload.input.image_base64.length} characters)`);
      console.log('  - image_base64_2:', payload.input.image_base64_2 ? `[base64 data] (${payload.input.image_base64_2.length} characters)` : 'not set');
      console.log('  - seed:', payload.input.seed);
      console.log('  - width:', payload.input.width);
      console.log('  - height:', payload.input.height);
      console.log('  - steps:', payload.input.steps || 'not set');
      console.log('  - guidance_scale:', payload.input.guidance_scale);
    }

    const requestBody = JSON.stringify(payload);
    
    try {
      const response = await this.fetchWithRetry(`${this.baseUrl}/run`, {
        method: 'POST',
        headers: this.getHeaders(),
        body: requestBody,
      });

      const responseText = await response.text();

      if (!response.ok) {
        throw new Error(`RunPod API error: ${response.status} - ${responseText}`);
      }

      const data = JSON.parse(responseText);
      console.log('âœ… Job submitted successfully, ID:', data.id);

      if (!data.id) {
        throw new Error('RunPod API did not return a job ID');
      }

      return data.id;
    } catch (error) {
      console.error('âŒ RunPod API call failed:', error);
      throw error;
    }
  }

  // ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ê°€ ì¬ì‹œë„ ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
  private isRetryableError(error: any): boolean {
    if (!error) return false;

    const errorMessage = error.message || '';

    // ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ì—ëŸ¬ë“¤ (ì¬ì‹œë„ ê°€ëŠ¥)
    if (errorMessage.includes('SocketError') ||
        errorMessage.includes('other side closed') ||
        errorMessage.includes('ECONNRESET') ||
        errorMessage.includes('ENOTFOUND') ||
        errorMessage.includes('timeout') ||
        errorMessage.includes('fetch failed')) {
      return true;
    }

    return false;
  }

  // ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ fetch wrapper
  private async fetchWithRetry(url: string, options: RequestInit, maxRetries: number = 3): Promise<Response> {
    let lastError: any;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        const response = await fetch(url, options);
        return response;
      } catch (error) {
        lastError = error;

        if (!this.isRetryableError(error) || attempt === maxRetries) {
          throw error;
        }

        console.log(`ğŸ”„ Retry attempt ${attempt}/${maxRetries} for network error:`, (error as any).message);
        await new Promise(resolve => setTimeout(resolve, 1000 * attempt)); // ì§€ìˆ˜ ë°±ì˜¤í”„: 1ì´ˆ, 2ì´ˆ, 3ì´ˆ
      }
    }

    throw lastError;
  }

  async getJobStatus(jobId: string): Promise<RunPodJobResponse> {

    const response = await this.fetchWithRetry(`${this.baseUrl}/status/${jobId}`, {
      method: 'GET',
      headers: this.getHeaders(),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`RunPod status API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();

    // ìƒíƒœê°€ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ë¡œê·¸ ì¶œë ¥
    if (data.status === 'COMPLETED' || data.status === 'FAILED') {
      console.log(`ğŸ“Š Job ${jobId} status:`, data.status);

      // ì™„ë£Œëœ ê²½ìš°ì—ë§Œ ê°„ë‹¨í•œ ì¶œë ¥ ì •ë³´ë§Œ ë¡œê·¸
      if (data.status === 'COMPLETED' && data.output) {
        const outputKeys = Object.keys(data.output);
        console.log(`ğŸ“Š Output keys:`, outputKeys);
      }
    }

    return data;
  }

  async waitForCompletion(jobId: string, maxWaitTime?: number): Promise<RunPodJobResponse> {
    const startTime = Date.now();
    const pollInterval = 5000; // 5 seconds
    const timeout = maxWaitTime || this.generateTimeout; // ì‚¬ìš©ì ì§€ì • íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©

    console.log(`â° Waiting for job completion with timeout: ${timeout / 1000}ì´ˆ`);

    while (Date.now() - startTime < timeout) {
      const status = await this.getJobStatus(jobId);

      if (status.status === 'COMPLETED') {
        console.log('âœ… Job completed successfully!');
        return status;
      }

      if (status.status === 'FAILED') {
        console.log('âŒ Job failed:', status.error);
        throw new Error(`Job failed: ${status.error}`);
      }

      if (status.status === 'IN_QUEUE' || status.status === 'IN_PROGRESS') {
        // ì§„í–‰ ìƒí™©ì€ 30ì´ˆë§ˆë‹¤ë§Œ ë¡œê·¸ ì¶œë ¥
        const elapsed = Math.floor((Date.now() - startTime) / 1000);
        if (elapsed % 30 === 0) {
          console.log(`â³ Job in progress... (${status.status}) - ${elapsed}ì´ˆ ê²½ê³¼`);
        }
        await new Promise(resolve => setTimeout(resolve, pollInterval));
        continue;
      }

      throw new Error(`Unknown job status: ${status.status}`);
    }

    throw new Error(`Job timeout: Maximum wait time (${timeout / 1000}ì´ˆ) exceeded`);
  }
}

export default RunPodService;